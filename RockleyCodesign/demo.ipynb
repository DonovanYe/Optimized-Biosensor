{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOPKLAWsGxzs"
      },
      "source": [
        "# Rockley Bio-Sensor Selection Codesign Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLfsNkyYdW_s"
      },
      "source": [
        "## Mount Google Drive and configure PYTHONPATH variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELSqWQtolLgH"
      },
      "source": [
        "**Before running:** Find the `optimized_bio_sensor` folder in Drive and use the `Add shortcut to Drive` option to add it to `MyDrive`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy8GhzqXtwYl",
        "outputId": "b4adb169-c407-4b3a-ef6b-3b6ae265b7f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/.shortcut-targets-by-id/1EaHvULJYewcfEpQ7wlYgmG1eRbVcahUv/optimized_bio_sensor/RockleyCodesign\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "# os.environ['PYTHONPATH'] += ':/content/gdrive/MyDrive/22FL/CS101-TA/optimized_bio_sensor/RockleyCodesign'\n",
        "os.environ['PYTHONPATH'] += ':/content/gdrive/MyDrive/optimized_bio_sensor/RockleyCodesign'\n",
        "os.environ['PYTHONPATH'] += ':/content/gdrive/MyDrive/optimized_bio_sensor/rockley'\n",
        "# %cd /content/gdrive/MyDrive/22FL/CS101-TA/optimized_bio_sensor/RockleyCodesign\n",
        "%cd /content/gdrive/MyDrive/optimized_bio_sensor/RockleyCodesign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jq2bKJndPTM"
      },
      "source": [
        "## Install necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLJrSPv2aNh7",
        "outputId": "316d42af-24ec-4d6c-da20-78839c4df7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "Building wheels for collected packages: pytorch\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "Installing collected packages: pytorch\n",
            "    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-cfr1_5yt/pytorch_9ae305b410754774be1c608c2f4f8c77/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-cfr1_5yt/pytorch_9ae305b410754774be1c608c2f4f8c77/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-sfrm8k0h/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.8/pytorch Check the logs for full command output.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.0+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.8.4-py3-none-any.whl (799 kB)\n",
            "\u001b[K     |████████████████████████████████| 799 kB 32.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.0+cu116)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2022.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 81.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.4.0)\n",
            "Collecting lightning-utilities!=0.4.0,>=0.3.0\n",
            "  Downloading lightning_utilities-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
            "Collecting tensorboardX>=2.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 81.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch-lightning) (3.19.6)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.0.4)\n",
            "Installing collected packages: torchmetrics, tensorboardX, lightning-utilities, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.4.2 pytorch-lightning-1.8.4 tensorboardX-2.5.1 torchmetrics-0.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.6-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 36.3 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 64.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 67.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 80.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 86.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 85.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 79.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 86.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 86.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 86.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 88.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 81.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=93eb2b838e01a61aea4f0974b65cc261c2beb53ba55ad840a3f950e366c973d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221122.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath>=0.1.7->fvcore) (4.4.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221122-py3-none-any.whl size=61484 sha256=8f5a7af0f526f7bc6e012e3bad4eaab0d29731d86525a797d8c3128be6b29e17\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/6e/e3/602889ca9c5c55020f8d205066445ac5b1b96df59f75170ca0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=47f64a59db64b3adf6805b8f4f1acca94fea751760d81774d4af5ecd479e61a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: portalocker, yacs, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221122 iopath-0.1.10 portalocker-2.6.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch\n",
        "!pip install torchvision\n",
        "!pip install pytorch-lightning\n",
        "!pip install wandb\n",
        "!pip install fvcore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fS8S9d-ddro"
      },
      "source": [
        "## Login to Weights and Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArnAwUltdhg6"
      },
      "source": [
        "Using Weights and biases is optional but highly recommended. It is an awesome platform for benchmarking, visualizing, and presenting results. To login, you need to create an account on https://wandb.ai/ and copy your API key. If you choose not to use it, comment line 32 in `codesign/engines/train_val_test.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7Sl0jsebHX1",
        "outputId": "188fa50c-7f64-457e-8435-0e53a80d5800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29k-owTFeI4u"
      },
      "source": [
        "## Train a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh_W43XkeOr2"
      },
      "source": [
        "To train a model is easy. Simply run `!python3 scripts/main.py -c CONFIG_FILE`, where `CONFIG_FILE` is the experiment configuration file in [YAML](https://en.wikipedia.org/wiki/YAML) format. The example below is a classic FashionMNIST classification experiment. Take a look at how to configurate the experiment in `configs/fashion_mnist_classification_demo.yaml`!\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6KiWyf3i1GI"
      },
      "source": [
        "Current default stopping criterion: the training will be stopped if either `val_test_loss` in config does not improve for 10 epochs (patience=10) or the epoch reaches `trainer.max_epochs` in config, whichever happens earlier. You can the patience on line 22 in `codesign/engines/train_val_test.py`. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codesign models use LOUPESampler as their sampler in their config file (or SetLOUPESampler for CNN but this is slow and results aren't particularly good)\n",
        "\n",
        "See `configs/LOUPEModel.yaml` for more details on particular specifications\n",
        "\n",
        "While training, PyTorch lightning will save the best model its seen so far in terms of val loss\n",
        "\n",
        "After a bit, you can use code from TestNNModels notebook to visualize the probability map from that checkpoint\n",
        "\n",
        "If the probability map stabilizes to a binary map (we saw that it did), you can then pull those indices in that stable binary map and use Subsampler as a sampler instead. This will only pass through those indices which allows you to downsize input size to regressor while keeping the same effect (helps with convergence + speed). See `configs/PreindexedLOUPEModel.yaml` for an example/directions\n",
        "\n",
        "At any point, you can stop training, tweak learning/batch rate/etc. to help speed up training, and re-run from that checkpoint by setting init conditions in those config files"
      ],
      "metadata": {
        "id": "n65DNGqR42vL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDP8ovVAChMe",
        "outputId": "4c903b54-2045-4b91-cbe1-e163cb631495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdonovan-ye\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/rockley_nonlinear_regression/wandb/run-20221122_040953-2jvu6e76\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrockley_nonlinear_regression\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/donovan-ye/rockley_codesign\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/donovan-ye/rockley_codesign/runs/2jvu6e76\u001b[0m\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/gdrive/.shortcut-targets-by-id/1EaHvULJYewcfEpQ7wlYgmG1eRbVcahUv/optimized_bio_sensor/RockleyCodesign/results/rockley_nonlinear_regression exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | sampler       | LOUPESampler       | 200   \n",
            "1 | predictor     | NonlinearRegressor | 22.1 K\n",
            "2 | train_loss    | MSELoss            | 0     \n",
            "3 | val_test_loss | MSELoss            | 0     \n",
            "-----------------------------------------------------\n",
            "22.3 K    Trainable params\n",
            "3         Non-trainable params\n",
            "22.3 K    Total params\n",
            "0.089     Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]-------> validation set: 32000 batches of size 1 (32000 samples in total) <-------\n",
            "-------> training set: 2000 batches of size 64 (128000 samples in total) <-------\n",
            "Epoch 41: 100% 34000/34000 [02:55<00:00, 193.29it/s, loss=3.29e+03, v_num=6e76]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train_mse_loss ██▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        val_mse_loss █▇▇▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 41\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train_mse_loss 3323.59399\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step 83999\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        val_mse_loss 3351.11743\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrockley_nonlinear_regression\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/donovan-ye/rockley_codesign/runs/2jvu6e76\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/rockley_nonlinear_regression/wandb/run-20221122_040953-2jvu6e76/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 scripts/main.py -c configs/LOUPEModel.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7FgRscIfu32"
      },
      "source": [
        "## Test a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5je1fD00iglL"
      },
      "source": [
        "After you train a model, your model (best performance with `val_test_loss`) will be saved in a folder with the same name as the `exp_name` in your config file. To test the model, run `!python3 scripts/main.py -c RUN_CONFIG_FILE -d DATA_CONFIG_FILE`, where `RUN_CONFIG_FILE` is the config file of the run and `DATA_CONFIG_FILE` is the config file of the data you want to test on. Usually, the test data is from the same dataset as the training/validation data, but in this way we allow mix-and-match training and testing by separating the two config files.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dtD_uu7l_YK"
      },
      "source": [
        "***Remember, test a model only after parameter tuning and model selection to avoid biases!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAQA2lcKiP4f",
        "outputId": "d4b3d837-9ef8-49f1-97b2-1fb316dabc3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "-------> test set: 40000 batches of size 1 (40000 samples in total) <-------\n",
            "Testing DataLoader 0: 100% 40000/40000 [02:30<00:00, 264.92it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "      test_mse_loss          23.66487693786621\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ],
      "source": [
        "!python3 scripts/test.py -c results/PreindexedLOUPEModel/config.yaml -d configs/default_testset_configs/PreindexedLOUPEModel.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5ruV-1tpIYZ"
      },
      "source": [
        "## Beyond (it's on you!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8nhzPSNpRlR"
      },
      "source": [
        "This example gives you an idea about how to start this codesign project. Now the stage is yours. Overall, you need to build this repo in the following ways:\n",
        "  - Write data class for loading the Rockley data in `codesign.data`\n",
        "  - Design customizd sampler for measurement selection in `codesign.samplers`\n",
        "  - Implement classification/regression algorithms in `codesign.predictors`\n",
        "  - Add new loss functions in `codesign.losses`\n",
        "  - Write configuration files according to your needs in `configs`\n",
        "\n",
        "Besides the essential to-dos above, you should also consider:\n",
        "  - Adding visualizations in validation and test procedures in `codesign.engines.callbacks`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}